{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master copy to merge each team members work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Businss Understanding \n",
    "This data came from real world microscopic images.  Each image is a blood smear from a patient that was then placed on a slide for imaging.  This data was collected with the intention of classifing Acute Lymphoblastic Leukemia (ALL).  This can be a difficult task in, due to the differences between healthy and cells with leukemia being extremely small.  Each image from the data set was analyzed by an expert oncologist.  \n",
    "\n",
    "With this data a simple prediction task could be to detect the existence of leukemic blasts (cancerous cells).  The upsides to this are clear, with reducing the work load on the doctors.  To be clear the intention is not to replace doctors, so the false negative rate will have to be extremely low.  But instead of a doctor having to look through hundreds of images, sometimes even of one patient, the program can predict what images are likely to have leukemic blasts, and then that will be reviewed by a certified onocologist.\n",
    "\n",
    "Liek disscussed above the false positive rate must be extremely low for this prediction algorithm to be useful.  Conversely the false positive rate can be substantially higher.  In other words it is completely acceptable for the algorithm to indicate there might be leukemic blasts, but it would be unaccetpable for the algorithm to miss even 5% of the leukemic blasts.  That being a 95% accuracy rating of positive (on an image basis not patient) and a 70% accuracy rate of negatives would be accceptable and useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "* read in your images as numpy arrays. Resizse and recolor images as necessary\n",
    "* Linearize the images to create a table of 1-D image features (each image should be one row)\n",
    "* Visualize several images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def gray_sacle(data):\n",
    "    return np.dot(data[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "def read_images(directories, verb = False):\n",
    "    \"\"\"Reads in the all and rem directoires under each directory in the list directories\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for direct in dirs:\n",
    "        if verb:\n",
    "            print(f\"Reading {direct}\")\n",
    "        direct_all = f\"{direct}\\\\all\"\n",
    "        for file in listdir(direct_all):\n",
    "            if verb:\n",
    "                print(f\"Reading file: {file}\")\n",
    "            image = Image.open(f\"{direct_all}\\\\{file}\")\n",
    "            data = np.asarray(image)\n",
    "            data = gray_sacle(data)\n",
    "            data = data.ravel()\n",
    "            X.append(data)\n",
    "            y.append([1])\n",
    "                \n",
    "        direct_rem = f\"{direct}\\\\rem\"\n",
    "        for file in listdir(direct_all):\n",
    "            if verb:\n",
    "                print(f\"Reading file: {file}\")\n",
    "            image = Image.open(f\"{direct_all}\\\\{file}\")\n",
    "            data = np.asarray(image)\n",
    "            data = gray_sacle(data)\n",
    "            data = data.ravel()\n",
    "            X.append(data)\n",
    "            y.append([0])\n",
    "                \n",
    "    return np.asarray(X), np.asarray(y)\n",
    "\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=6):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.7 * n_col, 2.3 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14544, 202500)\n",
      "Wall time: 5min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dirs = [\n",
    "    r'..\\archive\\C-NMC_Leukemia\\training_data\\fold_0',\n",
    "    r'..\\archive\\C-NMC_Leukemia\\training_data\\fold_1',\n",
    "    r'..\\archive\\C-NMC_Leukemia\\training_data\\fold_2'\n",
    "    #r'..\\archive\\C-NMC_Leukemia\\training_data\\fold_small'\n",
    "]\n",
    "X, y = read_images(dirs, verb=False)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reduction\n",
    "* Perform linear dimensionality reduction of the images using **principal components analysis**. Visulize the explained variance of each component. Analyze how many dimensions are required to adequately represent your image data. Explain analysis and conclusion.\n",
    "* Compare the representation using PCA and Randomized PCA. The method you choose to comapre dimensionality methods should quantitatively explain which method is better at reresenting the images with fewer components. Do you prefer one method over another? Why?\n",
    "* Perform **feature extraction** upon the images using any feature extraction technique (gabor filerts, ordered gradients, DAISY)\n",
    "* Does this feature extraction method show promise for your prediction task? Why? Use visualizations to analyze this questions. For example, visualize the differences **between statistics of extracted features** in each target class. Another option, use a heat map of the pairwise differences (ordered by class) among all extracted features. Another option, build a nearest neighbor classifier to see actual classification performance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work\n",
    "* Perform feature extraction upon the images using DAISY. Rather than using matching go the images with the total DAISY vector, you will instead use key point matching. You will need to investigate appropriate methods for key point matching using DAISY. NOTE: this often requires some type of brute force matching per pair of images, which can be computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
